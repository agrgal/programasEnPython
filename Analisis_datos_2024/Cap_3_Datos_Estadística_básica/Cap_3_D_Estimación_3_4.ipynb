{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab3b98e4-e5a2-498d-baed-a401f9a901cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095d0114-ab5a-43fd-b8e6-3b5cc5d752cc",
   "metadata": {},
   "source": [
    "# Estimaciones\n",
    "\n",
    "Consiste en estimar el valor de los parámetros de un conjunto de datos (media , varianza, etc. estimadas).\n",
    "\n",
    "### Media\n",
    "\n",
    "- Imaginemos unos datos aleatorios que sabemos que provienen de una distribución normal:  {0.33, −1.76, 2.34, 0.56, 0.89}\n",
    "- Su media es 0.472. Si hubiese algún valor atípico, su media se dispararía y, evidentemente no representaría los datos. \n",
    "- Si no hay valores atípicos, la función MSE (mean squared error) se minimiza.\n",
    "\n",
    "<center>$${\\color{Teal} \\mathbf{MSE = \\frac{1}{n} \\sum (\\overline{x} - \\mu)^2}}$$</center>\n",
    "\n",
    "- **n** es el número de veces que se estima la media. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "397b1482-e393-4638-9eb9-fd628384afe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.472\n"
     ]
    }
   ],
   "source": [
    "datos = [0.33, -1.76, 2.34, 0.56, 0.89]\n",
    "media = np.mean(datos)\n",
    "print(media)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c61fb-67ab-4fda-9f42-09427dfe850b",
   "metadata": {},
   "source": [
    "#### Estimando la media y calculando el error medio al cuadrado MSE\n",
    "\n",
    "- Cuantas más veces se estime (n) y cuantos más puntos tengamos, más pequeño será el error. Con esta rutina conseguimos en 200 tests (los puntos se obtiene de una distribución normal centrada en u de entre 1000 puntos al azar). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1cb5a53c-d1a0-4905-894e-1563531dfb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0009869659001695002\n"
     ]
    }
   ],
   "source": [
    "n = 200 # número de tests\n",
    "mu = 0 # media\n",
    "std = 1 # desviación típica; en las librerías le llamana loc. \n",
    "puntos = 1000 \n",
    "err = 0\n",
    "for i in range(n):\n",
    "    xp = np.random.normal(mu,std,puntos)\n",
    "    err += (xp.mean()-mu) ** 2\n",
    "print('MSE: {}'.format(err/n))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f47128d-c155-48b2-8a3f-b3953c2cfd68",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "### Varianza\n",
    "- Estimamos la varianza con las siguientes fórmulas (n-1 es mejor para muestras con pocos puntos). \n",
    "\n",
    "<center>$${\\displaystyle \\bar{\\sigma}^{2}={\\frac {1}{n}}\\sum _{i=1}^{n}\\left(x_{i}-{\\overline {x}}\\,\\right)^{2}} \\; \\; , \\; \\; {\\displaystyle \\bar{\\sigma}^{2}={\\frac {1}{n}}\\sum _{i=1}^{n-1}\\left(x_{i}-{\\overline {x}}\\,\\right)^{2}}$$</center>\n",
    "\n",
    "### Núcleo estándar (standard core)\n",
    "- Si queremos comparar dos conjuntos de datos, incluso si están en unidades distintas (aunque hay que evitarlo) se normaliza creando el **núcleo estándar**. A cada dato x le corresponde un z tal que:\n",
    "\n",
    "<center>$$z_i=\\frac{x_i-\\mu}{\\sigma}$$</center>\n",
    "\n",
    "- Estos datos convertidos tienen la ventaja de tener media 0 y desviación típica o varianza 1. Lo que heredan es la forma de los datos: si la distribución de X es normal o es asimétrica, así lo será Z.\n",
    "   \n",
    "### Covarianza\n",
    "- Mide de alguna manera la tendencia común de dos variables: \n",
    "\n",
    "<center>$$dx_i=x_i-\\mu_x \\;\\; ,  \\;\\; dy_i=y_i-\\mu_y \\Rightarrow Cov(x,y)=\\frac{1}{n} \\sum_{i=1}^{n}\\left ( dx_i \\cdot dy_i  \\right )$$</center>\n",
    "\n",
    "- En la covarianza, si ambas crecen el valor es positivo. Si negativo, una decrece y otra aumenta.\n",
    "\n",
    "## Correlación de Pearson\n",
    "\n",
    "- Si calculamos la covarianza de los núcleos estándar de X e Y:\n",
    "\n",
    "<center>$$\\rho_{x_i}=\\frac{x_i-\\mu_x}{\\sigma_x} \\;\\; ,  \\;\\; \\rho_{y_i}=\\frac{y_i-\\mu_y}{\\sigma_y} \\Rightarrow \\rho=\\frac{1}{n}\\sum_{i=1}^{n}\\left ( \\rho_{x_i} \\cdot \\rho_{y_i}  \\right )= \\frac{Cov(x,y)}{\\sigma_x \\cdot \\sigma_y }$$</center>\n",
    "\n",
    "- Obtenemos la correlación de Pearson, que está normalizada. Si existe una correlación de +1 ó -1 ambos datos están relacionados por una fórmula. Si ρ=0, **no quiere decir que no exista correlación**. Quiere decir que no existe una correlación de orden uno, pero puede haberla de otro orden de magnitud. La presencia de atípicos hace que la correlación no funcione bien.\n",
    "\n",
    "## Correlación de los rangos de Spearman\n",
    "\n",
    "- En esta correlación no se computan los datos, sino el rango de los datos ordenados. Por ejemplo, los valores X={10,20,40,30,5} tendrán un rango de ordenación {2,3,5,4,1} y los valores Y={-100,25,-2,30, 70} un rango de {1, 3 , 2 , 4, 5}.\n",
    "- Obtenemos una correlación de Pearson de 0.05 pero de Spearman de -0.2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d36d26-1f6f-4c8c-9fa7-16c50f8d4747",
   "metadata": {},
   "source": [
    "## Calculando correlación de Pearson y de Spearman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7ede2734-5dc5-4183-afd7-3ff0ffe501bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05111307737785618\n",
      "-0.19999999999999993\n"
     ]
    }
   ],
   "source": [
    "def corPearson(x,y):\n",
    "    if len(x)!=len(y): return -1000\n",
    "    sigma_x = np.std(x)\n",
    "    sigma_y = np.std(y)\n",
    "    media_x = np.mean(x)\n",
    "    media_y = np.mean(y)\n",
    "    resultado = 0\n",
    "    for i in range(0,len(x)):\n",
    "        resultado += (x[i]-media_x)*(y[i]-media_y)/ (sigma_x * sigma_y)\n",
    "    return resultado / len(x)\n",
    "\n",
    "def corSpearman(x,y):\n",
    "    inicio = [x,y]\n",
    "    s=[sorted(x),sorted(y)]\n",
    "    index=[]\n",
    "    for k in range(0,2):\n",
    "        m=[]\n",
    "        for i in s[k]:\n",
    "            m.append(inicio[k].index(i)+1)\n",
    "        index.append(m)\n",
    "    return corPearson(index[0],index[1])\n",
    "        \n",
    "        \n",
    "x=[10,20,40,30,5]\n",
    "y=[-100,25,-2,30, 70]\n",
    "print(corPearson(x,y)) # lo mismo que print(np.corrcoef(x,y)) \n",
    "print(corSpearman(x,y))\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a90f620-e253-4088-9b0c-03861fe64827",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
